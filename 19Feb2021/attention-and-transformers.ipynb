{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Eric Korman -> Cofounder/CSO @ Striveworks\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention and Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from itertools import product\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(scalars, weight):\n",
    "    last = scalars[0]\n",
    "    smoothed = []\n",
    "    for point in scalars:\n",
    "        smoothed_val = last * weight + (1 - weight) * point\n",
    "        smoothed.append(smoothed_val)\n",
    "        last = smoothed_val\n",
    "    return smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(dset):\n",
    "    dl = DataLoader(dset, batch_size=32)\n",
    "    all_preds, all_labels = [], []\n",
    "    for x, y in tqdm(dl):\n",
    "        all_preds.extend(model(x).argmax(1).cpu().numpy().tolist())\n",
    "        all_labels.extend(y.cpu().numpy().tolist())\n",
    "    \n",
    "    return (np.array(all_preds) == np.array(all_labels)).sum() / len(all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attention mechanism operates on sequences (or really sets) of vectors. Let $\\mathbb{R}^{L \\times d}$ denote the space of length $L$ sequences of vectors in $\\mathbb R^d$. For $v \\in \\mathbb{R}^{L \\times d}$ we denote the sequence as $(v_1, \\ldots, v_L), ~~ v_i \\in \\mathbb R^d$.\n",
    "\n",
    "The basic attention mechanism is the map\n",
    "$$\n",
    "\\operatorname{att} : \\mathbb{R}^{L_1 \\times d_1} \\times \\mathbb{R}^{L_2 \\times d_1} \\times \\mathbb{R}^{L_2 \\times d_2} \\to \\mathbb{R}^{L_1 \\times d_2}\n",
    "$$\n",
    "defined by\n",
    "$$\n",
    "[\\operatorname{att}(q, k, v)]_i = \\sum_j \\alpha_{ij}(q, k) v_j\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\alpha_{ij}(q, k) = \\operatorname{softmax}\\left(\\frac{q_i \\cdot k_1}{\\sqrt d_1}, \\ldots, \\frac{q_i \\cdot k_{L_2}}{\\sqrt d_1}\\right)_j.\n",
    "$$\n",
    "\n",
    "In words, $\\alpha_{ij}$ is the similarity between the ith element of the first sequence and the jth element of the second (normalized via softmax across the second sequence). The result of attention at index $i$ is then a weighted sum of all of the elements of $v$, weighted so that $v_j$ is favored if the similarity between $q_i$ and $k_j$ is large.\n",
    "\n",
    "### Bibliography\n",
    "This type of mechanism was first introduced in:\n",
    "\n",
    "Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. ***Neural machine translation by jointly learning to align and translate.*** ICLR 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(q, k):\n",
    "    \"\"\" Computes pairwise (in a batch) normalized inner products between Q and K.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    q : torch.Tensor\n",
    "        shape [N, L1, DK] where N is the batch size\n",
    "    k : torch.Tensor\n",
    "        shape [N, L2, DK]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        shape [N, L1, L2]\n",
    "    \"\"\"\n",
    "    alpha = torch.einsum(\"nik,njk->nij\", q, k) / q.shape[-1]**(1/2)\n",
    "    alpha = F.softmax(alpha, dim=-1)\n",
    "    return alpha\n",
    "\n",
    "def attention(q, k, v):\n",
    "    \"\"\" scalar dot product attention\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    q : torch.Tensor\n",
    "        shape [N, L1, DK] where N is the batch size\n",
    "    k : torch.Tensor\n",
    "        shape [N, L2, DK]\n",
    "    v : torch.Tensor\n",
    "        shape [N, L2, DV]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        shape [N, L1, DV]\n",
    "    \"\"\"\n",
    "    return torch.einsum(\"nij,njk->nik\", alpha(q, k), v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-head self-attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, $k$ and $v$ will come from the same underlying sequence $y \\in \\mathbb{R}^{L_2 \\times \\tilde d}$ via maps\n",
    "$K: \\mathbb R^{\\tilde d} \\to \\mathbb R^{d_1}, ~~ V: \\mathbb R^{\\tilde d} \\to \\mathbb R^{d_2}$:\n",
    "$$\n",
    "k = (K(y_1), \\ldots, K(y_{L_2})), ~~ v = (V(y_1), \\ldots, V(y_{L_2}))\n",
    "$$\n",
    "and similarly with $q$, with it coming from a sequence $x \\in \\mathbb R^{L_1\\times \\hat d}$ via a map $Q: \\mathbb R^{\\hat d} \\to \\mathbb R^{d_1}$.\n",
    "\n",
    "The names $q, k$, and $v$ stand for *query*, *key*, and *v* and this nomenclature helps in understanding the mechanism. For example, suppose we want to do a bulk query on something like a google image search. Think of:\n",
    "* $(x_1, \\ldots, x_{L_1})$ as the search terms (free text).\n",
    "* $Q$ as a word embedding, producting vectors.\n",
    "* $(y_1, \\ldots, y_{L_2})$ as a sequence of tuples of images and text descriptions in the database.\n",
    "* $K$ as taking $y_j$ to the word embeddings of the text descriptions.\n",
    "* $V$ as taking $y_j$ to the underlying image.\n",
    "\n",
    "Then if instead of softmaxing we took the argmax, the attention output at index $i$ would be the best image for the search term $x_i$.\n",
    "\n",
    "In many cases $y = x$, which leads to *self-attention*. Furthermore, it has been found useful to run multiple attention mechanisms in parallel, leading to *multi-head self-attention*. In this case each of the $h$ attention heads will output a sequence of vectors in $\\mathbb R^{d / h}$, where $d$ is the dimension of the vectors in $x$. These then get concatenated and to form a sequence of vectors in $\\mathbb R^d$ and then supercomposed via a linear map $\\mathbb R^d \\to \\mathbb R^d$.\n",
    "\n",
    "### Bibliography\n",
    "Multi-head self-attention was introduced in the work:\n",
    "\n",
    "Ashish Vaswani, et al. ***Attention is all you need.*** NIPS 2017.\n",
    "\n",
    "which is the paper that introduced transformers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "### PyTorch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, h, d):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        h : int\n",
    "            number of heads\n",
    "        d : int\n",
    "            dimension of the vectors/encodings\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # output of the Q, K, V maps are typically d // h so that introducting new heads\n",
    "        # does not add more parameters.\n",
    "        self.Qs = nn.ModuleList([nn.Linear(d, d // h) for _ in range(h)])\n",
    "        self.Ks = nn.ModuleList([nn.Linear(d, d // h) for _ in range(h)])\n",
    "        self.Vs = nn.ModuleList([nn.Linear(d, d // h) for _ in range(h)])\n",
    "        self.W = nn.Linear(d, d)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            shape [N, L, self.d]\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            shape [N, L, self.d]\n",
    "        \"\"\"\n",
    "        out = [attention(Q(x), K(x), V(x)) for Q, K, V in zip(self.Qs, self.Ks, self.Vs)]\n",
    "        out = torch.cat(out, dim=-1)\n",
    "        out = self.W(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We stay in the setting of self-attention and let $x \\in \\mathbb R^{L \\times d}$.\n",
    "\n",
    "### Positional encoding\n",
    "So far everything we have discussed is equivariant under permuting the elements of the sequence $x$ (i.e. we are operating on the set of the sequence). In NLP language we are using a \"bag of words\" approach. Obviously for many applications the order of elements is important and so the position of an element must be encoded. The idea of positional encoding is to produce for each index $i$ a vector in $\\mathbb R^d$ such that\n",
    "\n",
    "* Each component of the vector is in $[0, 1]$ (standard practice for neural networks).\n",
    "* The closeness of positional encodings correlates to closeness of indices.\n",
    "\n",
    "In the ***Attention is all you need*** paper they suggest the following encoding of position $i$\n",
    "$$\n",
    "pe(i) = \\left(\\sin(i), \\cos(i), \\sin(i / 10000^{2 / d}), \\cos(i / 10000^{2 / d}), \\ldots, \\cos(i / 1000 \\right)\n",
    "$$\n",
    "\n",
    "This gets added to the input $x$ before going through the attention layer.\n",
    "\n",
    "### Feed-forward NN\n",
    "For more expressivity we can add a simple MLP $FF: \\mathbb R^d \\to \\mathbb R^d$ that acts on each component of the sequence after the attention layer.\n",
    "\n",
    "### Putting it all together\n",
    "Putting it all together, the fundamental building block of a transformer is a map $\\mathbb R^{L \\times d} \\to \\mathbb R^{L \\times d}$ of the form\n",
    "$$\n",
    "x \\mapsto FF(\\operatorname{mhsa}(x + pe) + x + pe)\n",
    "$$\n",
    "which can then be composed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d, d_inter):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d, d_inter)\n",
    "        self.linear2 = nn.Linear(d_inter, d)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            shape [N, L, d]\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            shape [N, L, d]\n",
    "        \"\"\"\n",
    "        return self.linear2(torch.relu(self.linear1(x)))\n",
    "\n",
    "class TransformerLayer(nn.Module):\n",
    "    def __init__(self, d, d_inter, h):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        d : int\n",
    "            dimension of input vectors\n",
    "        d_inter : int\n",
    "            hidden layer dimension of MLP\n",
    "        h : int\n",
    "            number of heads\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadSelfAttention(h, d)\n",
    "        self.ff = FeedForward(d, d_inter)\n",
    "        self.linear = nn.Linear(d, 2)\n",
    "        \n",
    "        pe = torch.zeros(L, d)\n",
    "        position = torch.arange(0, L, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d, 2).float() * (-math.log(10000) / d))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.pe = pe\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.float() + self.pe\n",
    "        out = self.mha(x)\n",
    "        out = self.ff(x + out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do a very simple example of learning to classify sequences as Fibonacci sequences or not. We will use one, single-headed transformer layer and with no feedforward network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTransformer(nn.Module):\n",
    "    def __init__(self, d, d_inter, h):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadSelfAttention(h, d)\n",
    "        self.linear = nn.Linear(d, 2)\n",
    "        \n",
    "        pe = torch.zeros(L, d)\n",
    "        position = torch.arange(0, L, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d, 2).float() * (-math.log(10000) / d))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.pe = pe\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        out = self.mha(x + self.pe)\n",
    "        out =  x + self.pe + out\n",
    "        out = self.linear(out.sum(1))\n",
    "        return F.log_softmax(out, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in model: 462\n"
     ]
    }
   ],
   "source": [
    "h, d = 1, 10 # 5, 10\n",
    "N, L = 16, 6\n",
    "model = SimpleTransformer(d, 32, h)\n",
    "print(f\"Total number of parameters in model: {sum([p.numel() for p in model.parameters()])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FibDataset(Dataset):\n",
    "    \"\"\" Fibonacci dataset. At even indices it returns a Fibonacci sequence. At odd indices\n",
    "    it returns a permutation of a Fibonacci sequence or a sequence with the recursive defition\n",
    "    x_i = x_{i - 1} + x_{i - 3}\n",
    "    \"\"\"\n",
    "    def __init__(self, start_pairs):\n",
    "        self.start_pairs = start_pairs\n",
    "        self.seq_length = 6\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if index % 4 == 0 or index % 4 == 2:\n",
    "            label = 1\n",
    "            seq = self.gen_fib(self.start_pairs[index // 2])\n",
    "        elif index % 4 == 1:\n",
    "            label = 0\n",
    "            seq = self.gen_fib(self.start_pairs[(index - 1) // 2])\n",
    "            seq = np.take(seq, np.random.permutation(self.seq_length))\n",
    "        else:\n",
    "            label = 0\n",
    "            seq = self.gen_non_fib(self.start_pairs[(index - 1) // 2])\n",
    "            \n",
    "        return torch.tensor([[int(c) for c in format(s, \"010b\")] for s in seq]), label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 2 * len(self.start_pairs)\n",
    "\n",
    "    def gen_fib(self, start_pair):\n",
    "        ret = list(start_pair)\n",
    "        while len(ret) < self.seq_length:\n",
    "            ret.append(ret[-1] + ret[-2])\n",
    "        return ret\n",
    "    \n",
    "    def gen_non_fib(self, start_pair):\n",
    "        ret = list(start_pair)\n",
    "        while len(ret) < self.seq_length:\n",
    "            if len(ret) < 3:\n",
    "                ret.append(ret[-1] + ret[-2] + 1)\n",
    "            else:\n",
    "                ret.append(ret[-1] + ret[-3])\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_pairs = list(product(range(100), range(100)))\n",
    "train_data = random.sample(start_pairs, int(len(start_pairs) * .9))\n",
    "val_data = [t for t in start_pairs if t not in train_data]\n",
    "train_dset = FibDataset(train_data)\n",
    "val_dset = FibDataset(val_data)\n",
    "train_dl = DataLoader(train_dset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = SGD(params=model.parameters(), lr=1e-1)\n",
    "opt = Adam(params=model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc1157dbe9648c1935c72aed2f80614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2252.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_epochs = 4\n",
    "losses = []\n",
    "pbar = tqdm(total=len(train_dl) * n_epochs)\n",
    "for epoch in range(n_epochs):\n",
    "    for x, y in train_dl:\n",
    "        preds = model(x)\n",
    "        \n",
    "        loss = F.nll_loss(preds, y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        pbar.set_description(f\"[{epoch + 1} / {n_epochs}] loss: {loss:.4f}\")\n",
    "        pbar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa459eca810>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAyAklEQVR4nO3deXhU1fnA8e87M1kIYQsJ+xKQfRUaxV1QFAT3HZdaa4vWrYs/W+q+trbV1lr3rba2SrXVVgVFUQSVNYggi0BYDQJZ2EJC9vP7Y+6dubNlJjAhzOT9PA+PM/fezJwZk3fOnPOe94gxBqWUUonP1dwNUEopFR8a0JVSKkloQFdKqSShAV0ppZKEBnSllEoSnuZ64uzsbJObm9tcT6+UUglp6dKlJcaYnHDnmi2g5+bmkp+f31xPr5RSCUlEtkQ6p0MuSimVJKIGdBF5WUSKRGRlA9eMFZGvRGSViMyNbxOVUkrFIpYe+ivAxEgnRaQ98DRwrjFmKHBJXFqmlFKqUaIGdGPMPGBXA5dcAbxljNlqXV8Up7YppZRqhHiMoQ8AOojIpyKyVES+H+lCEZkqIvkikl9cXByHp1ZKKWWLR0D3AN8DJgMTgLtFZEC4C40xzxtj8owxeTk5YbNulFJKHaR4pC0WAqXGmHKgXETmASOBdXF4bKWUUjGKRw/9f8BJIuIRkQxgDLAmDo8b1todZTz24VpK9lc11VMopVRCiiVt8XVgATBQRApF5DoRuUFEbgAwxqwBPgBWAIuBF40xEVMcD9WG4v385ZMCSvdXN9VTKKVUQoo65GKMmRLDNX8A/hCXFkXhdgkAtfX1h+PplFIqYSTcSlGPFdDr6nWnJaWUckq4gG730GvqNKArpZRTwgX0FLe3ydpDV0qpQAkX0HUMXSmlwku4gG6PodfqkItSSgVIuIDu1klRpZQKK+ECuj2GXqsBXSmlAiRcQPf30HUMXSmlnBIuoHs0bVEppcJKuICuY+hKKRVewgV0HUNXSqnwEi6g6xi6UkqFl3ABXcfQlVIqvMQL6Lr0Xymlwkq4gO4vzqVDLkop5ZRwAT3V6qHrkItSSgVKvIDu8Ta5ulZ76Eop5ZRwAd3tElyiQy5KKRUs4QI6eHvp1RrQlVIqQCybRL8sIkUi0uDGzyJyjIjUisjF8WteeKlulw65KKVUkFh66K8AExu6QETcwO+AD+PQpqi0h66UUqGiBnRjzDxgV5TLbgH+AxTFo1HRpLpd1GgPXSmlAhzyGLqIdAcuAJ6J4dqpIpIvIvnFxcUH/Zwp2kNXSqkQ8ZgUfRz4lTEmaoQ1xjxvjMkzxuTl5OQc9BPqGLpSSoXyxOEx8oDpIgKQDUwSkVpjzH/j8NhhpbhdmraolFJBDjmgG2P62LdF5BXgvaYM5uCdFK3SHrpSSgWIGtBF5HVgLJAtIoXAvUAKgDHm2SZtXQSp2kNXSqkQUQO6MWZKrA9mjPnBIbUmRqkeFxXVtYfjqZRSKmEk7EpRLc6llFKBEjKgp7hFs1yUUipIggZ0HUNXSqlgiRvQdU9RpZQKkKABXaip1TF0pZRySsiA7nG7qNUeulJKBUjIgJ7iEs1yUUqpIAkZ0D1uF7U6KaqUUgESNKALNfXaQ1dKKaeEDOi69F8ppUIlZED3uFwYA3XaS1dKKZ/EDOhuAdBeulJKOSRkQE+xAnqt9tCVUsonIQO6x+Vttma6KKWUX0IG9BSPt9m6r6hSSvklZEBP9Y2h65CLUkrZEjKgp6e4AThQXdfMLVFKqSNHQgb01qnejZZ01yKllPJLyICekertoZdXaQ9dKaVsUQO6iLwsIkUisjLC+StFZIWIfC0i80VkZPybGSjVmhTVPHSllPKLpYf+CjCxgfObgFONMcOBB4Hn49CuBqW4NaArpVQwT7QLjDHzRCS3gfPzHXcXAj3i0K4GaQ9dKaVCxXsM/Trg/UgnRWSqiOSLSH5xcfFBP4ndQ6/SjaKVUsonbgFdRMbhDei/inSNMeZ5Y0yeMSYvJyfnoJ8r1TfkonnoSillizrkEgsRGQG8CJxljCmNx2M2RIdclFIq1CH30EWkF/AWcLUxZt2hNyk6uzhXtQ65KKWUT9Qeuoi8DowFskWkELgXSAEwxjwL3AN0BJ4WEYBaY0xeUzUY/LVctIeulFJ+sWS5TIly/kfAj+LWohjYY+hanEsppfwScqWoLw+9VidFlVLKlpAB3e0S3C6huk6X/iullC0hAzp4J0Y1bVEppfwSOKC7NMtFKaUcEjagp3lcmuWilFIOCRvQtYeulFKBEjqgaw9dKaX8Ejagp3pcOimqlFIOCRvQU9wurbaolFIOCRvQU92iQy5KKeWQsAFdx9CVUipQwgb0VE1bVEqpAAkb0DVtUSmlAiV2QNcsF6WU8knYgJ7q0UlRpZRyStyArkMuSikVIGEDuma5KKVUoMQN6JrlopRSARI2oOuQi1JKBYoa0EXkZREpEpGVEc6LiDwhIgUiskJERse/maFSPS7dU1QppRxi6aG/Akxs4PxZQH/r31TgmUNvVnS6Y5FSSgWKGtCNMfOAXQ1cch7wd+O1EGgvIl3j1cBIUtwu6uoNdfUa1JVSCuIzht4d+NZxv9A6FkJEpopIvojkFxcXH9KTpnq8TdeJUaWU8jqsk6LGmOeNMXnGmLycnJxDeqxUt7fpOo6ulFJe8Qjo24Cejvs9rGNNKsUK6DWa6aKUUkB8Avo7wPetbJfjgL3GmO1xeNwG+QK6TowqpRQAnmgXiMjrwFggW0QKgXuBFABjzLPATGASUABUANc2VWOd7DF0zUVXSimvqAHdGDMlynkD3BS3FsUoxS2AjqErpZQtoVeKgma5KKWULWEDeruMFABK91c3c0uUUurIkLABvWu7VgAUlVU2c0uUUurIkLABvW26d/i/rLK2mVuilFJHhoQN6G3SvUMuZZU1zdwSpZQ6MiRsQE/1uEjzuNinPXSllAISOKCDt5euPXSllPJK6IDeNt2jPXSllLIkdEBvk+7RSVGllLIkeEDXIRellLIleEDXHrpSStkSOqC3a5XC3gPaQ1dKKUjwgJ7VOpXd5dV464MppVTLlvABvbbesO+ADrsopVTCB3SAVdv3NnNLlFKq+SV0QLeX/z/w7upmbolSSjW/hA7o4wd3AmB493bN3BKllGp+CR3QRYQBnTM100UppUjwgA7QPiOVPRUa0JVSKqaALiITRWStiBSIyLQw53uJyBwRWSYiK0RkUvybGl6HjBR2V+iuRUopFTWgi4gbeAo4CxgCTBGRIUGX3QW8YYwZBVwOPB3vhkbSISOV3dpDV0qpmHroxwIFxpiNxphqYDpwXtA1Bmhr3W4HfBe/JjYsq3Uqeyqqqa/XxUVKqZYtloDeHfjWcb/QOuZ0H3CViBQCM4Fbwj2QiEwVkXwRyS8uLj6I5obqmJlGbb3RiVGlVIsXr0nRKcArxpgewCTgVREJeWxjzPPGmDxjTF5OTk5cnjg707u4qGR/VVweTymlElUsAX0b0NNxv4d1zOk64A0AY8wCIB3IjkcDo8nJTAOgWAO6UqqFiyWgLwH6i0gfEUnFO+n5TtA1W4HTAURkMN6AHp8xlSiy21gBvUwDulKqZYsa0I0xtcDNwCxgDd5sllUi8oCInGtddhvwYxFZDrwO/MAcphKIPTtkIAKbSyoOx9MppdQRyxPLRcaYmXgnO53H7nHcXg2cGN+mxaZVqps0j4s/zV7HDWP7kuZxN0czlFKq2SX8SlGAypp6AOatK2nmliilVPNJioB++4SBALrRhVKqRUuKgH7+KG9a/EerdzZzS5RSqvkkRUDvbGW6aAkApVRLlhQB3eN2cXL/bIrLKpu7KUop1WySIqAD9OjQim17DjR3M5RSqtkkTUDvk92akv3VWgJAKdViJU1AH9WrAwArCvc0b0OUUqqZJE1A75eTCcDG4vJmbolSSjWPpAnoHVqnktU6lQ3F+5u7KUop1SySJqAD9M1uzQbtoSulWqjkCug5rXXIRSnVYiVVQM9pk8buimotAaCUapGSKqB3yEilrt5QpLXRlVItUFIF9CFdvftUFxTpxKhSquVJqoDerX0rALbv1RIASqmWJ6kCepd26QDMWPEdudNmsHLb3mZukVJKHT5JFdDTU9y0z0hhzlrvdqZaTlcp1ZIkVUAH2OMooVtZU9eMLVFKqcMrpoAuIhNFZK2IFIjItAjXXCoiq0VklYi8Ft9mHpzaek1fVEq1HFEDuoi4gaeAs4AhwBQRGRJ0TX/g18CJxpihwM/i39TG23fA21vftucA/e6YqWPqSqmkFksP/VigwBiz0RhTDUwHzgu65sfAU8aY3QDGmKL4NvPg7Kv0BvQvCkqorTe8+NnGZm6RUko1nVgCenfgW8f9QuuY0wBggIh8ISILRWRiuAcSkakiki8i+cXFxQfX4iheve5YhnRtS7tWKey1eugZqW4Aqmrrm+Q5lVLqSBCvSVEP0B8YC0wBXhCR9sEXGWOeN8bkGWPycnJy4vTUgU7un8PMn57MMbkdKNx9gNvfXO6bKK3TMXWlVBKLJaBvA3o67vewjjkVAu8YY2qMMZuAdXgDfLNpm55C4e4DvLm0kLv+uxKAVI/35S7etItd5dXN2TyllIq7WAL6EqC/iPQRkVTgcuCdoGv+i7d3johk4x2CadYB67atUkKOZaS62VpawaXPLWDco58e/kYppVQTihrQjTG1wM3ALGAN8IYxZpWIPCAi51qXzQJKRWQ1MAe43RhT2lSNjkW4gF5eVccN/1gK4BtfV0qpZOGJ5SJjzExgZtCxexy3DfAL698RoYdV1wXgpWvyeOC91WzdVcHq7fuasVVKKdV0km6lqG14j3a+26cP7syOvZV8HZSHrnXTlVLJJGkDev9OmQH3w6Us6sSoUiqZJG1A97hd/O6i4bx780kA/PUHx4RcM+Y3Hx/uZimlVJNJ2oAOcNkxvXxDL+MGdeL+c4cGnNdaL0qpZJLUAT3YlWN6NXcTlFKqybSogO5xu7hx7FGMG+hfpfrNDs16UUolhxYV0AF+OXEQf732WO47x1swcuLjn8X18Str6qioro3rYyqlVCxaXEC3dXPkqX+wcjsAf1+wma2lFYf0uJc9v5Ah98yipk4LgSmlDq8WG9DHD+7suz1/QykfrNzOPf9bxYXPzPcdL91fxZv534b78YiWf7sHgEufWxCXdiqlVKxabEB3uYQv7z4DgNLyam74x5cAlOyv8l3zvYdmc/u/V3D/u6sa/fjLtu6JSzuVUipWLTagA2SmeSsfzFixPeB4QVFZwP2/frHZ1/NujKpa3dNUKXX4tOiAnuKWsMd/Ov0rcqfNCDh23lNfhL22rt5QXuWdBA3e4u77Ly2OQyuVUio2LTqgiwhf3XOG7/6SO8cDsOq72FMZH3xvNUPvnUVtXT0LNwYWmFy0aReVNf5e+rlPfs7f5m8+tEYrpVQEMVVbTGbtM1LZ/MjkiOcHd23Lmu37yGmTFvb8qwu3ANDvzvcZP7hTyPnC3Qfo1ykTYwwrCveyonAv15yQG7VdG4r3061dK1pZ2+cppVQ0LbqHHouJQ7tw7shuvn1JN5eU88j731BXb6ivNwHb2s1e490b+71bTuK1H40B4JbXlwGBxcHqo5QcqK83nP7YXH789/y4vpZ4qqqtI3faDC5yZAUppZpXi++hR5PVOoXXFpeyc18V+ypruO/dVXy6tphn526ga7v0sD8ztFtbCor2A7Bm+z7KKmt48pMC3/m1O8sY3LVtxOesqfcG/88LSuL4SuLr30sLAVi6ZXczt0QpZdMeepC/TBnFj0/u47uf1TqN0wZ5h1K2llZwoNo/Jr59byUAU47114g5Z2Q3RIT+ndv4js1bV8Jz8/w78q23gn2wwt0VfL6+hNq62IqGzVixvVE7L+2vqo1bqYN9B/yrYbWuvFJHBg3oQc4Z2Y07Jg323e/QOoVL8rx7ZG/bcyDszzirOKZ7/G/pU1eMBuCm174MuP5Waxgm2E3//JKrXlrE0HtnRW1ncVkVN732JSPv/9A3jh/No7PWMvHxz3h01tqYrm+IM0OoskZXxSp1JNCAHoaIIFa86tg6jZxM74To9a8uZdGmXSHXp3pcjLUKfm0sKfcd/17vDg0+z67yat8Y/NodZSwv3BtyzbY9B1j1XeDxOd8U8Q9HEL/7vyvDPv4bS77lmU83+O7PW1cMwJNzCgKuq62rZ+2OwNz7aNJT/JO1/1y0JWAuQSnVPGIK6CIyUUTWikiBiExr4LqLRMSISF78mtg8Hr/saMYOzKF3xwzaZYRuOH31cb255bR+3HO2t8jXY5eMBODMIf6SAl3apQf0ZOdPO813+99LCxn94Ee8+Jl3KOaLCOPlJz7yCZOf+Nx3v3R/Fde+soQ/f7w+6mv45X9W8LsPvvHdz0jzB+HFjg+mn7+xnAmPz6O4rIpYVTsmeR+ascb3OpRSzSdqQBcRN/AUcBYwBJgiIkPCXNcG+CmwKN6NbA7nHd2dV649lvQUN5mpgXPHbdI9PHj+MG47cyA/PMk73t4xM42V909g6il9A661h2u816TSua23t/9/by4H4LfvewPuvPXFDbbnmpcX892eA/xm5jdhz++rjDyWbq9Ydbv8/7vfWb7NV0Ds3eXfAfgmcmMRvKXfll2xFzUrq6yhNs7FyzYU72f8H+eyoTj216BUsomlh34sUGCM2WiMqQamA+eFue5B4HdAZRzbd0RwuQJXlJ5/dPew12WmeRAJvDbV7Qq43TY9tLdfXlXLp2sbDuhz1xXz6IeRx75nr94ZcP+Bd1f7bu8u9wb7GkcQ/sfCrZzzF2/Pv5OVYz/lhYUNtsFp0abARVQ1YfZsDecvH69n+H0f8qv/fB3zc8XigXdXU1C0n9MfmxvXx1UqkcQS0LsDzpKDhdYxHxEZDfQ0xgSul08ib1x/vO/2Jsc4eTTDu7fz3RYRLhgd+mFw5Yv+LzV3TR7MvNvH8fAFw0Kue+vLbXTv0Crg2Khe7YHQFMeXv9jku11m9d6LgoZUvrHGzTPTG5e9un3vgZAPoDeXFrI7hk23H/toHQD/+bKwUc8ZTYcww2JKtTSHPCkqIi7gj8BtMVw7VUTyRSS/uLjhHumR5phc/wRnbX3swwUXju7O7y4azrNXeTNefnLqUTx4fmCwXv3dPvp3ygTgupP60KtjBlcc24u3bjwhZB/UWSt3+G6PHZjD2zeeyIDOmXy4KrCH7rSv0ptimOZx+QqS2d7/ejsbi/0fUMu2Rs8rL6v0pywO6Jzpu/1Xx4fIwTpQXRdQLiFWndp61wSkpzTNPP/KbXu5938rueDpL9jciA/0hmwtrdAhIhVXsfz2bwN6Ou73sI7Z2gDDgE9FZDNwHPBOuIlRY8zzxpg8Y0xeTk5O8OkjmohwXN8sADq1Cb+gKNLPXXZMLyYO6+q7f/Vxvcm2MmeO7tme6rp69hyoYeLQLr4hGxFhdK8OXHNCLkvvGu97vLU7/dko9mOs27mf/VW15E6bEXZjjX0Hali/s4xtew4gwK2n9fOd+8k/A1MqL3h6Ppc82/DqT2eN+A9/fiqXWfMEjcmJD/5gsQ2+5wPO/NO8mB/HZk/SVtfWU1xWxf6qg9s16n9fbQs7l3DB01/wtwVbWLZ1D2Mf/fSgHjvYKX+Yo0NEKq5iCehLgP4i0kdEUoHLgXfsk8aYvcaYbGNMrjEmF1gInGuMOXLXrR+k6VOP56krRvNQmOGQxnr7xhOY/YtTOXOoNyumuKyKjpmpYa/tmJkWtk6MnUFjL3wCeH/lDjYG9fqmL9nKup3eY2VVtVx3cuDEbbAlmxvupb/wmbcnbk8X/O7iEfTrlMm2PZV8vr4kYmkD5wKk/VW1IeWF7YnSrbsqfI+xq7yaSX/+LOowl92rrzdw9UuLGHbvrKglFoJVVNfy0+lfcd3flviO7aus4UB1HTUxLvY6GMYY1u4oo2hf0k0/qcMsakA3xtQCNwOzgDXAG8aYVSLygIic29QNPNJMHtE17MRmY/XMyqBfp0zGDvAH446twwd08NeJsd12xgCmTfQugLrkez18x/dWVHOa1evr3TGDzDQP64v2B6RPtmuVwjcPTgx4vNd/fFzAfWfw3bG3kutfzefbXRV851hctem3/qJmXdqmM3vNTq56aREvf7GJP364NiQNstYKsN2t7f92BY25//WLzb7bD7y3mlcXbmH26p2s3r4voHSC0/qdZewqrw4I+PbcQFkje+mPfegd39/i2IZwxH0fMuHxxn9jaIzPC0qY8Pg8TvzdJ036PM1hV3k13395ccDGMarpxDTgaIyZaYwZYIw5yhjzsHXsHmPMO2GuHZuMvfOmMqSbv6ZLx8zwFR3BW/DL6ZbT+/vy4ycO6+I7/rcF/gVHQ7q25Ycn9WFzSTkp1grWP19+NBC4MAjguL5ZzLt9nO++c2z3D7PWMmvVTv6xaAvPzwufb965rX8Y6qEZa3jikwKOeXg2NXX1FJVVUlNX7ytpYKduLg5apPWRI1Pnlfmbufu/K32585EmUc/40zxGP/hR2AVfs1fvjHlv1w9Wbuelz/1zAJtLyn0rg7eGScksayBNFGDWqh3M+aYo4nnnOLy90ramzviKvjWl+nrDeyu+Cyhj0VT+sXAL89YV84rjw1o1HV0pegRpaLXlsO7tGNWrPWkeF4vuOD3gnIhwnZUP7xz/ffKK0RyV05p6A8usIlo9OmSEfXwRoVfHDM4e4R3rP/dJ/4YedjDdW1FD2wgZMfUR6rms+m4fxz78McPuncXMr707Q6VYqZw/nf5VwLWLN4cGZefD/mdpw5kxrYI+pG57c3nAStmGBKdRPjRjNSc+ErnH/Ico5ROuf3Up176yJOL5fy7yf/DurvB/UznqjpkBWU9N4b2vt3Pza8u44OkvfBukR1NZUxewmCxWaVZHoqq2js0l5TE/XzBjDLNW7TgsH0KJTAP6EeTivB4Nnn/7xhNZ+9BZAb1h291nD+Gq4/xFwnpmtcLtEo7K8WahPGENWUTapclmZ9WccFR2yLkDNXW+x1l8Z+CHSqQ/tKus4FRVW89t1mIqZ0mENdtDi4Wd3N//3M5vCre9udz3gbVs624+XLUj4OcmWx9GToW7Y1vwZH9rsAUPcQG8cu0x3GJNKP99wRZyp82gqOzgxr3teQiAnXsDH2PBxlIqqmv540frIgbRon2V3Pzalwc1+WtPXn+zo8y3l240g+7+IOKuXQ2xA/oLn23iomfmc8M/vmz0ojJjDMf/9hOuf3Upf5q9rtFtaEk0oB8BPvvlOObePvaQx+YfPG+YLy+9dL+319e7Y2CPvG+OP83wiSmjQh6jY2YaI63MGwgc597nyGJJcwf2hh+9dCRDHcNHtnABp2dWBj2zvOPoZ/35M9/xo3JaM2l4F0r2+5/z8dmBJQ4efG81lz23gAuens/UV5cGnCuvquXtG08IOCYIxWVVzI9SinjswNBJ52CnDsjhF2cMCDgWrQbOvHXFIdk/wcXanJlLtqfnbOCJj9fzRv63IecAfvavr3hvxXYuPoh69I0p8QDeRW0Q/sM3mjTHt6ZS63dpZyOf/6XPN7HDmjAu3R99rUNLpgH9CNAzK4PeHVsf8uOICI9fdjQAFVaPuY3jQ+L+c4cGpAueMbgz4XRsncq8dcXkTpvB6Ac/8h2f41hMlJ4a+KuTmeZhxq0ns+E3k+iVlcFdkwcTSU1dPd/uCqxcuamknA3F5bRO9TC4S5sIP+kNLsHj5def6s3aueaEXEb16sDvLxpBqtUz3LGvkjve/porXlxE7rQZIYG9sqaOz9YXU1ZZQ06bNH56ev+Iz+0t2iYBaxKi+f7Lixl5/4cBufXOTcmzM1N5b0XoMMRKqyBbpJz8+Ru8K3W/2VHGujAfCJEYY3giQh2gfZU1YZ/vmU/DT0jHwrlS2rZjb/iqpZG863y/2kROHFAa0JNOF2vTDbsH7HR0z/YB91ulurlyTK+QXmf7VqHfFE7q5x8GuWBUd9I84bfGc7uEeb8cx49O7huyKMr22fqSoPvFjLNyu0vLq3n4guH8a2pg1o2z5nywM4d0YfMjkzmub0cALj2mJ+seOotj+2Qxd11xwLDNXxzZMvX1hkF3f8DVLy3mi4JS2qR7Igb0aWcN8t12pnU6F1k1ZEHQfrO2rAiZTdFKQTid+ad5MU/+7mggNXLEfR8y6O4PQo53yDj4ICphRvhifc9szkniWFYjN8aKwj0BBewSnQb0JJPmcfPKtcfw1k9ODDkX7g/z4QuGc2tQEJuzNnT8+Iox/oB68fcaHuu3nTOym+/2Hy4e4bvdJt1D3xz/N5KrX1oc8HOtUt2M6duRiUP92Tu/nDAw4vP06BD64QXQxvo24nHU4kmzVpLur6ol7+HZvuNbd1XQJj0lpG7PqvsncNfkwfzwxD6Esy/MYqrcaaEVMK796xJf6p79LemyvJ70dExSnzaoE2P6ZAX8XHARNNugoG8xsfbSj/+tf6I321r3sKu8OiAdNXj1ahfHzlyxfnDYZn69I+RYeVXsE5vGGL7e5i8f/Ub+oZeMqK6tZ87aIurqDRc+PZ9nPt1AQVHjykcfqTSgJ6GxAzuF3dS6fevYxug9Yb4mTxrun3A84aiOMT1OVutU1jwwkf/ddCKX5PXknZu9HzJnDesaEGSdnNkyaxy7KzW0WXa4SWKAy47xrmAtLqsiq3UquR0zfBk2w+6dFZIHb2fwDLR2mxo3MIfWaR5+dHJf3xAOwJs3+Ov62FUu31vxHef85fMGM5XyHprN8m/3MKZPFukpLh65aDg3jD3Kd/7C0d1D1gM4PzCMMWws3k9lTZ0v196edGxMpUyA/p0yefC8Yb6ffcuRFupMqayrN7y+eGvY9oRTtK+Sfy3xXz97TWhJivJGTOTua2RvPhZPfrKea/+6hKPumOlbGzH+j/PYtudAg6mmiUADegtgT4y2ibDcPtjlx/Rs8HxwRcmGtEp1M9Ia6hnRoz0FD5/FGUM6c80JuWGvv2mcvyzBVWN6A+ASb978k1eETuI2xE7R3F1Rw6AubejcNp29FTVMeT58Vck2VkB/8PxhDO/ejmeu+l7Y60b2aO+7bW/Fd/Nry/h6214mP/FZ2J+x3Tp9GdV19Qzq0tYaj8/i9xd5v71kZ6bhcgnXO0owO3vofX49k9Mem8uP/uZf5rH83jMRaVzBOICZPz3Z96F/6XMLePRDf/aInX9fXlXLhc/MD9iRKlp5h5tfW8av/vN1g9lF4SbK31n+XdhJ13DB/1Br6az6Lvzk7omPfMK1ryxJ6Po6GtBbgDdvOJ7Xf3xczIH4Z+MHhD0+f9ppfHzbqYfUFrv3f+WY3qx9aCJz/m8sn/9qHL+cOJANv5nEMbn+IYerj+/NuSO7Mdda8HT2CP8QzqbfTqJ1A712CCwcluZx0a5VCos37woYz85q7a9R3ybN+w3m2D5ZvHvLSSGLr2ypHhebfjsJ8O7+5Py6/o0j62XO/41l/cPesXzbltIKaurqAyYLL8nrwexfnOqbA7j19P6+OQv7G4AzsDkra6anuOnWrlXA6lbwppGWNrA6M8XtCvstDqBw9wEWbSxl6L2zWP7tnoBz2/dWkjttBo9YdfznbygJCPJ2e/dUhAZ+e5go3Bj6ra8vC8h4cj5fsI0lBx9wK2vq+DhKLzx4wVsi0YDeAnRqk87xMQ6TgHdi0/b7i0bw9JXeSpHd2rfy5bXHQ5rHTZ/s1vTokMGNY/sFPC94g9UTU0bRM8s/zmwPh4gIS+4az8r7J0R8fOfQUcn+asqrQwOJS/AFtsaUEXZ+ODoXYTllpnlIcbs41zGXALBw4y5SPP6fFxH6dfK/r63TPPzjR2MY3LWt7xuAsyJmsKraOt5eto3NJeXssALg5c8v4HsPzQ64Lnj8O9JQVUlZFZ+uCz8p++u3vAuwnp27gVcXbuGKFxYF7JFrf8sJ7oVvfmQyH/zsFLIz03zj9VtLK6JuMH6RIy3TXi19oPrgN0cJ3s4xXHVO50KvQ1VVW8dpj37Kx2GGnppC4wphqxZj2d1nUFNX7ytLe6T490+O9+UiZ6TG/us7pGtbPgrzR5WZ5vGNP09fvJW7zw7ZjCui7u1bsW3PAV+KqNP1p/T1TTp2CtMTDteDDbZuZxlrtu/ji4ISdobJTrnT2szcztu3q0B+efcZvv1pjTG+D5+H3vNuemIPvUX6BvLWsm0hx8YP7sTsNUUBG6Xbe9nOXVfMa4u2csWYXr402XU7y3wfUuMd6bG5HTPYXFpOQVEZ4/84j5+PHxDwDaaiupYvCko5Y0hgSu2fLz+aTtY3qV3lh1IXxv9B+sW00+jaNp391bW8mV/Ig9b7Y/+/2VRSTp/sQ0sn3lJawcaScu59ZxWnR0gTjiftoauwOrROPeKCOXjz6nMb8Uf24vfzmHJsL+48e3DA+DzA5OFdfdsMAowf0rg/uC8ce8Q6TRjamV9PGuwLpOHex29j2LLPnmC98sVF/OKN5SHn7cVfFwZtmuLMWLE/bPI37/LV+Zk2aRDBctqk8eYNx4ed8D65fza/v3hkQJuC3fG2t+duT17f879V5FnfEOyy0wBd27dix75K3lnuzS3/0+x1ATtl/Wz6V/z47/ks3bKL7Y589VMH5PiytEqiLC5atLGUq15c5Bv+uey5BTxlbYy+3pEN1L19K1wuoW16Ctcc35vJ1sT/7vJq3sj/lnGPfsqijaX8bPoyfvS3Jbz0+aaAn49FlTX/ULi7cbn3B0t76CqpjR/S2Reorz0hl95ZGYwb1ImaunpfIB/Vsz1z1hZz2xmRUyNjcc7Ibry7/LuQbw7OsgI3jTuKp+ZsiEv2xmprcu+xS0by1pf+XrXd0wTYc6CGLaUVXPzsAt+xKxw5/VeM6cVri7ZSXFbFMblZYfPGR/fqQPtWKbRKcXOggc1HjDEBi6ZsaY4MoS5t05i1tzLi4qYPrQJtu8trfCunB3dtS3tHym20Me5n527g84ISFm/cxdG92rNo0y4WbdrFTeP6Mc0aMjonaBjM43bx1JWj2fD4PHZX1PDLf68A4Ff/WcFma35i9poicjtm8KmjiF001XWHt/aM9tBVi+FyCeOHdMbtkoDhhkcuGsGfLhtJr47hC5fF4urjetPZGloJHsrIdlTRvH1CaO+4MZwLn+xhCRHhmuN7+447V9LuLq9mUlDmjXP8f27QAiZnBo8tLcWFyyW+fPTRvUKvAW+mSjibHRO2Xdq1iqnI1/QlW3l45hoAbp8QOEm/YGMpxhiMMSzYUBoyDm9n5RSVVbFoY/jgH2kBWYeM1IBduzYHTTZvLq3gpc83xZwmWuXIENreyBWyB0MDumrxOrdN54JRsS2WCmYvOCqvrqW3NRQUPMabEiavP9IKUadwWSgDrEnhW0/rx/mj/EMt9583zFdx0+lsayPwSOwVsPZz3ezYzeraE3MB70pc8Nfrd1bsvH3CQLpYQ0rB1TNtg7v6a/x0axfbMN7sNUW+1bLh3r+564rp8+uZTHlhYUBpAPAP++zYVxlQN+fOt/0VNSMVqWufkeKrORPJg++tZvwfY9tpqsoxEf3dnqbfwEQDulKH4MR+3jHnHh0yfMXJtu4K7YndMWmQb1/ZT247lY9+fkrUx/7X1ONCJgcnDe/CHy4ewU2n9Qu5/u6zh/j2po3VWcO6MKZPFn+2agBlpHroa30wjezRns2PTPZNbto7arVJ93D9KX259bR+3DSuH7+5MPIOXm6XcJFjjL9re/+q3jOGdI7Y23ey0zkBfm6l1Dpz8d92LIoqq6zhEystMXhY55+LtvpSJyPVTmpoSCmaR97/hgfeXR2wE5ezhz6/oARjTKOrTTaGjqErdQhOG9SJJ6aMYuLQLlRaf8h2z9Zp6in+FaF9Y0z97JuTyXNXfY++d8wEvNUxRYRL8iIv/Lr/vKFc8cIi+ua0Dkh1XHzn6SzcuIuqoIDlcbv41/XHBxwb0aMdG0vKQ2rc25PRKW4Xv57kL742bmAnhnVvy8pt3jH9K8f0YuzATozq1Z6MVHfAEE+HDP9q5QtHdees4V19pRKOye0Qsv3hT8YeFdBDnzisC3+avc63whMCi8b996vwwz42t0saXOncmBo6TvX1hmfnemvvuwTusrKlqh3B+7GP1rGvsoYXPtvE3394LKcMiP++ytpDV+oQiAjnjuxGqsdF2/QUNj8ymUsbCLiN5awtE5zPHs4JR2Xz1T1n8O7N/h2ufnHGADq1Sefckd0a/DCw3T5xEGcO6cwERy0d8KZ+QmjGhojw9x+O8d1/+ILhnDGkM9mZaSETxO0chd/s8ek3bzie1qluHjp/eEhbnBOqAAMjVOJcusU7Vp4VoZDYo5d4s3S27qoI2QjFyU6x7JnVivvO8aewnjaoE0vuHO9LFQVvzR77m0Klo1e+otCf6x48X2DXwW+qgmDaQ1fqCPfeLSf5MlpiYWeEbPrtpEaVabB1b9+K57+fF3J8TB9vzzbchuX2nECkGj02Zzlnu+DbMblZrHpgIvX1hrNHdOWMIZ194/GpntA+Z5/s1iGlDi56ZgGbH5lMRZjFY9ed1Me3FqCsspadDWxK8tSVo9haWkF/a67inJHd+M3Mb/jZ+P7ktEnjwtHdfZO14K9V41yLsHjzLuZ8U8S4QZ2YvyF8HX7nxu7xpD10pY5ww7q349Io9XXCOZhg3pAu7dJZ+9BEX9GzYPl3jSf/rvENPoZzNXC7oDLNLpfw5BWjffng4a4B+Lmj3LOz7n5lTZ1vDPztG09gwtDOPHnFKO4+e0jABLM9NBROmsftC+bg3fDlsUtH+lYrd8xMC7vJSfCOXfb2g3Y6aa+swAyq4DUR8RJTQBeRiSKyVkQKRGRamPO/EJHVIrJCRD4Wkd7hHkcpldjSPO6IHxTZmWkB+eIHy1myoXv70NLI2Y4MIWdZ50F3f8Cz1h6yA7u04bmr83z1fyLVrTkYUx3F0wAmPD6P1WEKiznTFN+5+UTfa3G7JGQoKV6iPqqIuIGngLOAIcAUEQleH70MyDPGjAD+Dfw+3g1VSiWHubeP5X83hdbrd8psoDxBtiM4Z6R6uNWR8fOdVcsmPWgDlo4xpInGKj3FzYxbT+LB8/3ZPbe/6V/Ja2/t6Fxk1T4jldHWXrrpHlfcvz3ZYvmYOBYoMMZsNMZUA9OB85wXGGPmGGPsDPyFwMEl9Sqlkl7vjq19JZUjseu2hA3o1kItu2LlkKC9bFuluEM2KnEGUOeE8cEa2q0dVx/X27eHr73yd/rU43ypow/N8I6127n+9odKeYQN1eMhloDeHXDuVFtoHYvkOuD9cCdEZKqI5ItIfnHxwaUHKaWS3/Du7QB/9UanDhkp/OCEXN9GI8HZONFyyQ9lRXCwy4Kyho7NzQrYjQv88wB2sbamFNeBHBG5CsgD/hDuvDHmeWNMnjEmLycn/jmYSqnkcOfkwfxlyqiw5ZpFhPvOHerr5YsIb994QsRtAm32jlQZUeroN8agroHfDlwuIc3jZvYvTvWtRj17hHeS1+1q+hyUWNIWtwHOj6Ee1rEAIjIeuBM41RhzKPUtlVItXKc26SEFtBoyqleHBmvGA/z3phOZv6E0bCmBgzXUMdzj3AO3X6dMvr5vAjV19b5UzXC11+MtloC+BOgvIn3wBvLLgSucF4jIKOA5YKIxJrE35VNKJSR7svT4vuFXgvbNyYx5lW6sUtwu0lNcVNbU8+zVgVsWpqe4A+YA0qyJ2uByDvEUNaAbY2pF5GZgFuAGXjbGrBKRB4B8Y8w7eIdYMoE3rcmHrcaYc5us1UopFSTHmiyti7ILUrzNu30cRWXRByUmD+/K28sKuXty7JuoNJZE2wKqqeTl5Zn8/PzoFyqlVAyMMfz54/VcNLpHwLaFyUZElhpjQpfyokv/lVJJQkQibnDeUujSf6WUShIa0JVSKkloQFdKqSShAV0ppZKEBnSllEoSGtCVUipJaEBXSqkkoQFdKaWSRLOtFBWRYmDLQf54NhB+s76WSd+PQPp++Ol7ESgZ3o/expiw5WqbLaAfChHJj7T0tSXS9yOQvh9++l4ESvb3Q4dclFIqSWhAV0qpJJGoAf355m7AEUbfj0D6fvjpexEoqd+PhBxDV0opFSpRe+hKKaWCaEBXSqkkkXABXUQmishaESkQkWnN3Z7DQUQ2i8jXIvKViORbx7JE5CMRWW/9t4N1XETkCev9WSEio5u39YdORF4WkSIRWek41ujXLyLXWNevF5FrmuO1xEOE9+M+Edlm/Y58JSKTHOd+bb0fa0VkguN4wv8tiUhPEZkjIqtFZJWI/NQ63jJ/P4wxCfMP756mG4C+QCqwHBjS3O06DK97M5AddOz3wDTr9jTgd9btScD7gADHAYuau/1xeP2nAKOBlQf7+oEsYKP13w7W7Q7N/dri+H7cB/xfmGuHWH8naUAf6+/HnSx/S0BXYLR1uw2wznrNLfL3I9F66McCBcaYjcaYamA6cF4zt6m5nAf8zbr9N+B8x/G/G6+FQHsR6doM7YsbY8w8YFfQ4ca+/gnAR8aYXcaY3cBHwMQmb3wTiPB+RHIeMN0YU2WM2QQU4P07Soq/JWPMdmPMl9btMmAN0J0W+vuRaAG9O/Ct436hdSzZGeBDEVkqIlOtY52NMdut2zuAztbtlvIeNfb1t4T35WZrGOFle4iBFvR+iEguMApYRAv9/Ui0gN5SnWSMGQ2cBdwkIqc4Txrvd8YWm3/a0l+/5RngKOBoYDvwWLO25jATkUzgP8DPjDH7nOda0u9HogX0bUBPx/0e1rGkZozZZv23CHgb79flnfZQivXfIuvylvIeNfb1J/X7YozZaYypM8bUAy/g/R2BFvB+iEgK3mD+T2PMW9bhFvn7kWgBfQnQX0T6iEgqcDnwTjO3qUmJSGsRaWPfBs4EVuJ93fZM/DXA/6zb7wDft2bzjwP2Or56JpPGvv5ZwJki0sEajjjTOpYUguZJLsD7OwLe9+NyEUkTkT5Af2AxSfK3JCICvASsMcb80XGqZf5+NPesbGP/4Z2lXod3hv7O5m7PYXi9ffFmICwHVtmvGegIfAysB2YDWdZxAZ6y3p+vgbzmfg1xeA9exzuMUIN3bPO6g3n9wA/xTgoWANc29+uK8/vxqvV6V+ANWl0d199pvR9rgbMcxxP+bwk4Ce9wygrgK+vfpJb6+6FL/5VSKkkk2pCLUkqpCDSgK6VUktCArpRSSUIDulJKJQkN6EoplSQ0oCulVJLQgK6UUkni/wEZFUomDRZJdgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(smooth(losses, .9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec8b0a48ed442d29237836b633e97de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=563.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9458333333333333"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_accuracy(train_dset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Val accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29327e24aba44fc99217d89821d932b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=63.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_accuracy(val_dset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-attention heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84c3de9bccae49cb9cd6f25273820b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "alphas = np.zeros((6, 6))\n",
    "for x, y in iter(tqdm(val_dset)):\n",
    "    x_pe = x.float().unsqueeze(0) + model.pe\n",
    "    q, k, v = model.mha.Qs[0](x_pe), model.mha.Ks[0](x_pe), model.mha.Vs[0](x_pe)\n",
    "    alphas += alpha(q, k)[0].detach().numpy()\n",
    "\n",
    "alphas /= len(val_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa45a163950>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
